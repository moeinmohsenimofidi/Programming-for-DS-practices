{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "0c52553f5cb7a74adca1f2281a25086ef34cae33"
   },
   "source": [
    "# Polynomial regression \n",
    "### Linear and polynomial regression with the SALARY dataset\n",
    "You'll be using different types of regression to predict the salary of employes, based on historical salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a3519bc2b7fe0aa582b226adbb05209a28098b2"
   },
   "source": [
    "**1. Importing modules needed for the work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #this will ignore the warnings.it wont display warnings in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "32e59994b46a6f6389a1e02df0f676e45aaca859"
   },
   "source": [
    "**2. Importing the salary data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "49b751ec4833c29e0e2c9775fd9a1e84ed22bc7f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Position_Salaries.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1aa5a8fc7398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Position_Salaries.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Position_Salaries.csv'"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('Position_Salaries.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cede036d5c17cab94473c3e176030708e553fa7c"
   },
   "source": [
    "We can see that the dataset has 10 levels and the corresponding salary paid to the employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### We only have one usable feature in this dataset\n",
    "> The features 'Position' and 'Level' are redundant.\n",
    "> The **regressor** is the column 'Level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e953780a87ba00cc3b4ffd8c33f6d3c10afcf17d"
   },
   "outputs": [],
   "source": [
    "# extracting the regressor/column/feature 'Level'\n",
    "X=dataset.iloc[:,1:2].values  \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### We now need to extract the regressand, that is the variable that we eventually want to be able to predict\n",
    "> the **regressand** is the column 'Salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the column 'Salary'\n",
    "y=dataset.iloc[:,2].values    \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b9b82d15b089d36d28a3290d7ef55648f034025"
   },
   "source": [
    "**3. Splitting the data into training and test data**\n",
    "> Typically at this point we should be splitting the dataset into train and test set. So that we can test out our model after training. However in this simple example we only have few data points. So we´ll be using all of them for training. \n",
    "\n",
    "> **This is a very bad thing to do!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e4291138e946645616fef10c4969727c4c174cd3"
   },
   "outputs": [],
   "source": [
    "# uncomment the following to create the training and testing datasets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ba90b731925db7b5a626704034e68ee01fcf04f"
   },
   "source": [
    "**4. Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "beebebdf23e60324b73167ed3a552ed07a295b66"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c4372269d27081227c51712db22a056d24c4532"
   },
   "source": [
    "**5. Visualizing Linear Regression result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "521aaed1e040e904e52fee4d0fcf7d738059f53e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,y,color='red')\n",
    "plt.plot(X,lin_reg.predict(X),color='blue')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0e3eefeea5c2754d11f03adcdd6de1603bf0e8d"
   },
   "source": [
    "**6. Polynomial Regression**<br>\n",
    "Since our data is distributed in a non linear way, we'll try fitting it with polynomial curves, to get more accurate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0aecda366253387f74619f915631ecbd1ee388e7"
   },
   "outputs": [],
   "source": [
    "# polynomial curve of degree 2\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg2=PolynomialFeatures(degree=2)\n",
    "X_poly=poly_reg2.fit_transform(X)\n",
    "lin_reg_2=LinearRegression()\n",
    "lin_reg_2.fit(X_poly,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "34b0fca99bb31397fe574e3f777cdb59e41e2b36"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,y,color='red')\n",
    "plt.plot(X,lin_reg_2.predict(poly_reg2.fit_transform(X)),color='blue')\n",
    "#plt.plot(X,lin_reg_3.predict(poly_reg3.fit_transform(X)),color='green')\n",
    "plt.title('Polynomial Regression with degree=2')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Third-degree Polynomial Regression**<br>\n",
    "Since our data is still not fitting very well, we'll try fitting it with a higher-degree polynomial (degree=3), to get more accurate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd4f3e4674ffa3121e0687f2a8c4a6a73f2119df"
   },
   "outputs": [],
   "source": [
    "# Polynomial curve of degree 3\n",
    "poly_reg3=PolynomialFeatures(degree=3)\n",
    "X_poly3=poly_reg3.fit_transform(X)\n",
    "lin_reg_3=LinearRegression()\n",
    "lin_reg_3.fit(X_poly3,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b433ea49abdf2cad45deb52c1204fe7e5d2f279a"
   },
   "source": [
    "**8. Visualizing third-degree polynomial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "34b0fca99bb31397fe574e3f777cdb59e41e2b36"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,y,color='red')\n",
    "#plt.plot(X,lin_reg_2.predict(poly_reg2.fit_transform(X)),color='blue')\n",
    "plt.plot(X,lin_reg_3.predict(poly_reg3.fit_transform(X)),color='green')\n",
    "plt.title('Third-degree Polynomial Regression')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed401376a83b2831d3403942961ec39c66a926fe"
   },
   "source": [
    "**8. Predicting the salary of an employee with each of the 3 curves**\n",
    "Let´s use the three models to make predictions, to get a feel as to the accuracy we have achieved.\n",
    "> We now want to predict the salary of an employee comprised into a new level 6.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e025d178fd3bf04fe4f58edb3f7a10bc640bddc"
   },
   "outputs": [],
   "source": [
    "lin_reg.predict([[6.5]])  # We are assuming the level of the employee is 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0a42f27e221b562deb8911c29438ea20fa414e3"
   },
   "outputs": [],
   "source": [
    "lin_reg_2.predict(poly_reg2.fit_transform([[6.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3b44264e69a08f4d712c77ae2611f5b653ce34c"
   },
   "outputs": [],
   "source": [
    "lin_reg_3.predict(poly_reg3.fit_transform([[6.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51d98165862813930d0fa957454f6024fd064cc9"
   },
   "source": [
    "We can clearly see that the Polynomial Regression models fit much better, compared to the Linear Regression Model. As we increase the degree of the polynomial regression the correlation increases. **Linear regression overshoots** by a large amount, ending up with a 6.5-level employee that is predicted to earn much more than the actual salary of a 7-level employee. **Not a good model!!**\n",
    "\n",
    "> At the end of this notebook, you are required to compute the errors of each of the models more accurately, looking at the metrics introduced in one of the earlier notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and underfitting\n",
    "\n",
    "**You should not be tempted into using high-degree polynomials though!!**\n",
    "\n",
    "We always need to aim for the minimal possible degree (linear regression when possible), which has two benefits:<br>\n",
    "* it is much faster to compute (particularly on big datasets)\n",
    "* it avoids over-fitting\n",
    "\n",
    "Look at the following example to appreciate the problem at hand in a qualitative way.\n",
    "\n",
    "![PA Work Flow](./figures/underfitting_and_overfitting.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for this assignment\n",
    "1. First, solve this exercise in the ´incorrect´ way: don't split the dataset into training and testing sets. Tune the polynomial model. Write a script (set of functions) that, given the dataset, automatically generates all the polynomial models of degrees 1 to 10. For each model, compute MSE and R2_score. Plot the error functions (error vs degree_value). Determine the optimal degree_value.\n",
    "2. Now, reuse the code you have developped, to solve the same tuning exercise in the ´correct´ way. Split the dataset into training (70% of points) and testing (30% of points), and repeat the tuning as for point 1. Determine the optimal degree_value.\n",
    "3. Tuning for point 2. Change the ratio of the training set starting from 20% up to 100%, finding the optimal degree_value for each setup. \n",
    "4. Write your considerations about this exercise in a markdown cell. Compare and contrast the different results achieved for points 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
